{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Faces dataset decompositions\n",
    "\n",
    "This example applies to `olivetti_faces_dataset` different unsupervised\n",
    "matrix decomposition (dimension reduction) methods from the module\n",
    ":py:mod:`sklearn.decomposition` (see the documentation chapter\n",
    "`decompositions`).\n",
    "\n",
    "\n",
    "- Authors: Vlad Niculae, Alexandre Gramfort\n",
    "- License: BSD 3 clause\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "\n",
    "Loading and preprocessing the Olivetti faces dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /home/ange/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from numpy.random import RandomState\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn import cluster\n",
    "from sklearn import decomposition\n",
    "\n",
    "rng = RandomState(0)\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "faces, _ = fetch_olivetti_faces(return_X_y=True, shuffle=True, random_state=rng)\n",
    "n_samples, n_features = faces.shape\n",
    "\n",
    "# Global centering (focus on one feature, centering all samples)\n",
    "faces_centered = faces - faces.mean(axis=0)\n",
    "\n",
    "# Local centering (focus on one sample, centering all features)\n",
    "faces_centered -= faces_centered.mean(axis=1).reshape(n_samples, -1)\n",
    "\n",
    "print(\"Dataset consists of %d faces\" % n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a base function to plot the gallery of faces.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_col = 2, 3\n",
    "n_components = n_row * n_col\n",
    "image_shape = (64, 64)\n",
    "\n",
    "\n",
    "def plot_gallery(title, images, n_col=n_col, n_row=n_row, cmap=plt.cm.gray):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=n_row,\n",
    "        ncols=n_col,\n",
    "        figsize=(2.0 * n_col, 2.3 * n_row),\n",
    "        facecolor=\"white\",\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "    fig.set_constrained_layout_pads(w_pad=0.01, h_pad=0.02, hspace=0, wspace=0)\n",
    "    fig.set_edgecolor(\"black\")\n",
    "    fig.suptitle(title, size=16)\n",
    "    for ax, vec in zip(axs.flat, images):\n",
    "        vmax = max(vec.max(), -vec.min())\n",
    "        im = ax.imshow(\n",
    "            vec.reshape(image_shape),\n",
    "            cmap=cmap,\n",
    "            interpolation=\"nearest\",\n",
    "            vmin=-vmax,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.colorbar(im, ax=axs, orientation=\"horizontal\", shrink=0.99, aspect=40, pad=0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our data. Gray color indicates negative values,\n",
    "white indicates positive values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery(\"Faces from dataset\", faces_centered[:n_components])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition\n",
    "\n",
    "Initialise different estimators for decomposition and fit each\n",
    "of them on all images and plot some results. Each estimator extracts\n",
    "6 components as vectors $h \\in \\mathbb{R}^{4096}$.\n",
    "We just displayed these vectors in human-friendly visualisation as 64x64 pixel images.\n",
    "\n",
    "Read more in the `User Guide <decompositions>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenfaces - PCA using randomized SVD\n",
    "Linear dimensionality reduction using Singular Value Decomposition (SVD) of the data\n",
    "to project it to a lower dimensional space.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The Eigenfaces estimator, via the :py:mod:`sklearn.decomposition.PCA`,\n",
    "    also provides a scalar `noise_variance_` (the mean of pixelwise variance)\n",
    "    that cannot be displayed as an image.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_estimator = decomposition.PCA(\n",
    "    n_components=n_components, svd_solver=\"randomized\", whiten=True\n",
    ")\n",
    "pca_estimator.fit(faces_centered)\n",
    "plot_gallery(\n",
    "    \"Eigenfaces - PCA using randomized SVD\", pca_estimator.components_[:n_components]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative components - NMF\n",
    "\n",
    "Estimate non-negative original data as production of two non-negative matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_estimator = decomposition.NMF(n_components=n_components, tol=5e-3)\n",
    "nmf_estimator.fit(faces)  # original non- negative dataset\n",
    "plot_gallery(\"Non-negative components - NMF\", nmf_estimator.components_[:n_components])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent components - FastICA\n",
    "Independent component analysis separates a multivariate vectors into additive\n",
    "subcomponents that are maximally independent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_estimator = decomposition.FastICA(\n",
    "    n_components=n_components, max_iter=400, whiten=\"arbitrary-variance\", tol=15e-5\n",
    ")\n",
    "ica_estimator.fit(faces_centered)\n",
    "plot_gallery(\n",
    "    \"Independent components - FastICA\", ica_estimator.components_[:n_components]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse components - MiniBatchSparsePCA\n",
    "\n",
    "Mini-batch sparse PCA (`MiniBatchSparsePCA`) extracts the set of sparse\n",
    "components that best reconstruct the data. This variant is faster but\n",
    "less accurate than the similar :py:mod:`sklearn.decomposition.SparsePCA`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pca_estimator = decomposition.MiniBatchSparsePCA(\n",
    "    n_components=n_components, alpha=0.1, max_iter=100, batch_size=3, random_state=rng\n",
    ")\n",
    "batch_pca_estimator.fit(faces_centered)\n",
    "plot_gallery(\n",
    "    \"Sparse components - MiniBatchSparsePCA\",\n",
    "    batch_pca_estimator.components_[:n_components],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary learning\n",
    "\n",
    "By default, :class:`MiniBatchDictionaryLearning` divides the data into\n",
    "mini-batches and optimizes in an online manner by cycling over the\n",
    "mini-batches for the specified number of iterations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dict_estimator = decomposition.MiniBatchDictionaryLearning(\n",
    "    n_components=n_components, alpha=0.1, max_iter=50, batch_size=3, random_state=rng\n",
    ")\n",
    "batch_dict_estimator.fit(faces_centered)\n",
    "plot_gallery(\"Dictionary learning\", batch_dict_estimator.components_[:n_components])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster centers - MiniBatchKMeans\n",
    "\n",
    "`MiniBatchKMeans` is computationally efficient and implements on-line\n",
    "learning with a `partial_fit` method. That is why it could be beneficial\n",
    "to enhance some time-consuming algorithms with  `MiniBatchKMeans`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_estimator = cluster.MiniBatchKMeans(\n",
    "    n_clusters=n_components,\n",
    "    tol=1e-3,\n",
    "    batch_size=20,\n",
    "    max_iter=50,\n",
    "    random_state=rng,\n",
    "    n_init=\"auto\",\n",
    ")\n",
    "kmeans_estimator.fit(faces_centered)\n",
    "plot_gallery(\n",
    "    \"Cluster centers - MiniBatchKMeans\",\n",
    "    kmeans_estimator.cluster_centers_[:n_components],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor Analysis components - FA\n",
    "\n",
    "`Factor Analysis` is similar to `PCA` but has the advantage of modelling the\n",
    "variance in every direction of the input space independently\n",
    "(heteroscedastic noise).\n",
    "Read more in the `User Guide <FA>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_estimator = decomposition.FactorAnalysis(n_components=n_components, max_iter=20)\n",
    "fa_estimator.fit(faces_centered)\n",
    "plot_gallery(\"Factor Analysis (FA)\", fa_estimator.components_[:n_components])\n",
    "\n",
    "# --- Pixelwise variance\n",
    "plt.figure(figsize=(3.2, 3.6), facecolor=\"white\", tight_layout=True)\n",
    "vec = fa_estimator.noise_variance_\n",
    "vmax = max(vec.max(), -vec.min())\n",
    "plt.imshow(\n",
    "    vec.reshape(image_shape),\n",
    "    cmap=plt.cm.gray,\n",
    "    interpolation=\"nearest\",\n",
    "    vmin=-vmax,\n",
    "    vmax=vmax,\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Pixelwise variance from \\n Factor Analysis (FA)\", size=16, wrap=True)\n",
    "plt.colorbar(orientation=\"horizontal\", shrink=0.8, pad=0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition: Dictionary learning\n",
    "\n",
    "In the further section, let's consider `DictionaryLearning` more precisely.\n",
    "Dictionary learning is a problem that amounts to finding a sparse representation\n",
    "of the input data as a combination of simple elements. These simple elements form\n",
    "a dictionary. It is possible to constrain the dictionary and/or coding coefficients\n",
    "to be positive to match constraints that may be present in the data.\n",
    "\n",
    ":class:`MiniBatchDictionaryLearning` implements a faster, but less accurate\n",
    "version of the dictionary learning algorithm that is better suited for large\n",
    "datasets. Read more in the `User Guide <MiniBatchDictionaryLearning>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the same samples from our dataset but with another colormap.\n",
    "Red indicates negative values, blue indicates positive values,\n",
    "and white represents zeros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery(\"Faces from dataset\", faces_centered[:n_components], cmap=plt.cm.RdBu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous examples, we change parameters and train\n",
    "`MiniBatchDictionaryLearning` estimator on all images. Generally,\n",
    "the dictionary learning and sparse encoding decompose input data\n",
    "into the dictionary and the coding coefficients matrices.\n",
    "$X \\approx UV$, where $X = [x_1, . . . , x_n]$,\n",
    "$X \\in \\mathbb{R}^{m×n}$, dictionary $U \\in \\mathbb{R}^{m×k}$, coding\n",
    "coefficients $V \\in \\mathbb{R}^{k×n}$.\n",
    "\n",
    "Also below are the results when the dictionary and coding\n",
    "coefficients are positively constrained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary learning - positive dictionary\n",
    "\n",
    "In the following section we enforce positivity when finding the dictionary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pos_dict_estimator = decomposition.MiniBatchDictionaryLearning(\n",
    "    n_components=n_components,\n",
    "    alpha=0.1,\n",
    "    max_iter=50,\n",
    "    batch_size=3,\n",
    "    random_state=rng,\n",
    "    positive_dict=True,\n",
    ")\n",
    "dict_pos_dict_estimator.fit(faces_centered)\n",
    "plot_gallery(\n",
    "    \"Dictionary learning - positive dictionary\",\n",
    "    dict_pos_dict_estimator.components_[:n_components],\n",
    "    cmap=plt.cm.RdBu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary learning - positive code\n",
    "\n",
    "Below we constrain the coding coefficients as a positive matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pos_code_estimator = decomposition.MiniBatchDictionaryLearning(\n",
    "    n_components=n_components,\n",
    "    alpha=0.1,\n",
    "    max_iter=50,\n",
    "    batch_size=3,\n",
    "    fit_algorithm=\"cd\",\n",
    "    random_state=rng,\n",
    "    positive_code=True,\n",
    ")\n",
    "dict_pos_code_estimator.fit(faces_centered)\n",
    "plot_gallery(\n",
    "    \"Dictionary learning - positive code\",\n",
    "    dict_pos_code_estimator.components_[:n_components],\n",
    "    cmap=plt.cm.RdBu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary learning - positive dictionary & code\n",
    "\n",
    "Also below are the results if the dictionary values and coding\n",
    "coefficients are positively constrained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pos_estimator = decomposition.MiniBatchDictionaryLearning(\n",
    "    n_components=n_components,\n",
    "    alpha=0.1,\n",
    "    max_iter=50,\n",
    "    batch_size=3,\n",
    "    fit_algorithm=\"cd\",\n",
    "    random_state=rng,\n",
    "    positive_dict=True,\n",
    "    positive_code=True,\n",
    ")\n",
    "dict_pos_estimator.fit(faces_centered)\n",
    "plot_gallery(\n",
    "    \"Dictionary learning - positive dictionary & code\",\n",
    "    dict_pos_estimator.components_[:n_components],\n",
    "    cmap=plt.cm.RdBu,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
