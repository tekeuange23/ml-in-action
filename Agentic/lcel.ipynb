{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ff7bbf",
   "metadata": {},
   "source": [
    "### LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import LangChain components\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough, RunnableLambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf45f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     Env setup and Gemini model initialization     '''\n",
    "load_dotenv() \n",
    "\n",
    "# Check if the API key is loaded\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    print(\"Error: GOOGLE_API_KEY not found in environment variables.\")\n",
    "    exit()\n",
    "\n",
    "# models: ['gemini-2.5-pro', 'gemma-3-27b-it']\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemma-3-27b-it\", \n",
    "    temperature=0.7, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a0a98c",
   "metadata": {},
   "source": [
    "### 1. simple invocation (basic prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4071ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first person to walk on the moon was **Neil Armstrong** on July 20, 1969. \n",
      "\n",
      "He was commander of the Apollo 11 mission and famously said, \"That's one small step for [a] man, one giant leap for mankind\" as he stepped onto the lunar surface. \n",
      "\n",
      "While Buzz Aldrin followed him shortly after, Armstrong was the *first* to do so.\n"
     ]
    }
   ],
   "source": [
    "# This is the most basic way to call the model\n",
    "result = llm.invoke(\"Who was the first person to walk on the moon?\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab2d82",
   "metadata": {},
   "source": [
    "### 2. build chain with the prompt template (Sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66035bea",
   "metadata": {},
   "source": [
    "#### ---> sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835a297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode?\n",
      "\n",
      "Because light attracts bugs! \n",
      "\n",
      "üòÇ\n"
     ]
    }
   ],
   "source": [
    "# This is the most basic way to call the model\n",
    "\n",
    "# Create a template for our prompt. The {topic} part is a variable.\n",
    "template = \"Tell me a short joke about {topic}.\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"topic\"])\n",
    "\n",
    "# Create the chain by piping the prompt to the language model\n",
    "# The output of the prompt will be the input for the llm\n",
    "chain = prompt | llm\n",
    "\n",
    "# Invoke the chain by passing the value for our 'topic' variable\n",
    "response = chain.invoke({\"topic\": \"a programmer\"})\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4b96f",
   "metadata": {},
   "source": [
    "#### ---> adding output parser for cleaner output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f3d4857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of response: <class 'str'>\n",
      "Response:\n",
      "Why did the cat sit on the computer?\n",
      "\n",
      "...To keep an eye on the mouse! \n",
      "\n",
      "üòÇ\n"
     ]
    }
   ],
   "source": [
    "# StrOutputParser() simply extracts the string content from the AIMessage\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Rebuild the chain, adding the parser at the end\n",
    "chain_with_parser = prompt | llm | parser\n",
    "\n",
    "# Invoke the new chain\n",
    "clean_response = chain_with_parser.invoke({\"topic\": \"a cat\"})\n",
    "\n",
    "print(f\"Type of response: {type(clean_response)}\")\n",
    "print(\"Response:\")\n",
    "print(clean_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb63a1cc",
   "metadata": {},
   "source": [
    "#### ---> advance chain (passing through input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f90d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you want to see both the original question and the answer?\n",
    "# We can use RunnablePassthrough to pass the input topic along the chain.\n",
    "print(\"\\n=========        Chain with Passthrough       =========\")\n",
    "\n",
    "final_chain = (\n",
    "    {\"joke\": prompt | llm | parser} \n",
    "    | RunnablePassthrough()\n",
    ")\n",
    "\n",
    "# The result is now a dictionary containing the generated joke\n",
    "result_dict = final_chain.invoke({\"topic\": \"a robot\"})\n",
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c07c8",
   "metadata": {},
   "source": [
    "### 3. parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d7bec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DEFINE THE INPUT TEXT ---\n",
    "input_text = \"\"\"\n",
    "The new SuperGraphX 5000 is a revolutionary graphics card. \n",
    "It delivers breathtaking visuals and unparalleled performance, making every game an immersive experience.\n",
    "However, its high price point of $1200 might be a deterrent for budget-conscious builders. \n",
    "The power consumption is also noticeably high, requiring a robust power supply.\n",
    "\"\"\"\n",
    "\n",
    "# --- BUILD THE PARALLEL CHAIN (Your exact idea, formalized) ---\n",
    "\n",
    "# This is the canonical way to write what you proposed.\n",
    "# We define a dictionary where each value is a separate chain.\n",
    "# We add StrOutputParser to get clean string outputs.\n",
    "parallel_chain = RunnableParallel({\n",
    "    'summary': ChatPromptTemplate.from_template('Summarise this text in one sentence: {text}') | llm | parser,\n",
    "    'translation': ChatPromptTemplate.from_template('Translate this text into French: {text}') | llm | parser,\n",
    "    'sentiment': ChatPromptTemplate.from_template('What is the overall sentiment in this text? (positive, negative or neutral): {text}') | llm | parser,\n",
    "    'keywords': ChatPromptTemplate.from_template('Extract 5 main keywords from this text, separated by commas: {text}') | llm | parser,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68d628d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Executing 4 tasks in parallel on the same text ---\n",
      "\n",
      "Parallel execution took: 75.76 seconds\n",
      "\n",
      "--- Results ---\n",
      "\n",
      "[Summary]:\n",
      "The SuperGraphX 5000 is a high-performing graphics card offering stunning visuals, but its steep $1200 price and high power consumption may limit its appeal to serious gamers with substantial budgets and capable systems.\n",
      "\n",
      "[French Translation]:\n",
      "Here are a few options for the translation, ranging from more literal to slightly more fluid. I've included notes on the nuances:\n",
      "\n",
      "**Option 1 (More Literal):**\n",
      "\n",
      "> La nouvelle SuperGraphX 5000 est une carte graphique r√©volutionnaire.\n",
      "> Elle offre des visuels √©poustouflants et des performances in√©gal√©es, transformant chaque jeu en une exp√©rience immersive.\n",
      "> Cependant, son prix √©lev√© de 1200 $ pourrait √™tre un frein pour les constructeurs soucieux de leur budget.\n",
      "> La consommation d'√©nergie est √©galement notablement √©lev√©e, n√©cessitant une alimentation robuste.\n",
      "\n",
      "* **Strengths:** Very accurate to the original meaning.\n",
      "* **Weaknesses:**  A little bit stiff in places. \"Un frein\" is perfectly correct, but can sound a bit formal.\n",
      "\n",
      "**Option 2 (More Fluid & Common):**\n",
      "\n",
      "> La nouvelle SuperGraphX 5000 est une carte graphique r√©volutionnaire.\n",
      "> Elle propose des graphismes √† couper le souffle et des performances exceptionnelles, rendant chaque jeu incroyablement immersif.\n",
      "> Toutefois, son prix de 1200 $ risque de d√©courager les utilisateurs qui ont un budget limit√©.\n",
      "> Sa consommation d'√©nergie est √©galement assez √©lev√©e et exige une alimentation √©lectrique puissante.\n",
      "\n",
      "* **Strengths:**  Sounds more natural in French.  \"√Ä couper le souffle\" is a common idiom for \"breathtaking.\" \"D√©courager\" is a more common way to say \"deter.\" \"Puissante\" is a good fit for \"robust\" in this context.\n",
      "* **Weaknesses:** Slightly less literal than Option 1, but the meaning is preserved.\n",
      "\n",
      "**Option 3 (Slightly more marketing-focused):**\n",
      "\n",
      "> La SuperGraphX 5000, nouvelle carte graphique, est une v√©ritable r√©volution.\n",
      "> Elle offre des images spectaculaires et des performances in√©gal√©es pour une immersion totale dans vos jeux.\n",
      "> Son prix, 1200 $, pourrait cependant √™tre un obstacle pour les configurations plus modestes.\n",
      "> Elle consomme √©galement beaucoup d'√©nergie et n√©cessite une alimentation de qualit√©.\n",
      "\n",
      "* **Strengths:**  Sounds like something you'd read in a product description. Uses stronger adjectives (\"spectaculaires,\" \"totale\").\n",
      "* **Weaknesses:**  A bit more interpretive.\n",
      "\n",
      "\n",
      "\n",
      "**Key Differences & Explanations:**\n",
      "\n",
      "* **\"Breathtaking visuals\":**  \"Visuels √©poustouflants\" (Option 1) is accurate. \"Graphismes √† couper le souffle\" (Option 2) and \"images spectaculaires\" (Option 3) are more idiomatic and sound better.\n",
      "* **\"Unparalleled performance\":** \"Performances in√©gal√©es\" is a good direct translation. \"Exceptionnelles\" (Option 2) is also very common.\n",
      "* **\"Deterrent\":** \"Frein\" (Option 1) is correct but a bit formal. \"D√©courager\" (Option 2) and \"obstacle\" (Option 3) are more natural.\n",
      "* **\"Budget-conscious builders\":** \"Constructeurs soucieux de leur budget\" (Option 1) is accurate. \"Utilisateurs qui ont un budget limit√©\" (Option 2) and \"configurations plus modestes\" (Option 3) are more common phrasing.\n",
      "* **\"Robust power supply\":** \"Alimentation robuste\" (Option 1) is fine. \"Alimentation √©lectrique puissante\" (Option 2) and \"alimentation de qualit√©\" (Option 3) are more natural.\n",
      "\n",
      "\n",
      "\n",
      "**Recommendation:**\n",
      "\n",
      "I recommend **Option 2** as the best overall translation. It strikes a good balance between accuracy and natural-sounding French.  However, the best option depends on the *context* of the translation. If it's a very technical document, Option 1 might be preferable. If it's marketing material, Option 3 would be a good choice.\n",
      "\n",
      "[Sentiment]:\n",
      "The overall sentiment is **slightly positive**. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Strong Positives:** The text leads with very enthusiastic praise (\"revolutionary,\" \"breathtaking,\" \"unparalleled,\" \"immersive\"). These are powerful positive descriptors.\n",
      "* **Acknowledged Negatives:** The negatives (price and power consumption) are presented as *drawbacks* to an otherwise excellent product. They are framed as considerations, not deal-breakers.\n",
      "\n",
      "While the price and power consumption are downsides, the initial and more impactful impression is overwhelmingly positive due to the strong language used to describe the card's performance.\n",
      "\n",
      "[Keywords]:\n",
      "Graphics card, SuperGraphX 5000, performance, price, power consumption.\n"
     ]
    }
   ],
   "source": [
    "# --- EXECUTE THE CHAIN AND MEASURE TIME ---\n",
    "start_time = time.time()\n",
    "# The input dictionary key 'text' is passed to every prompt template in the parallel_chain\n",
    "results = parallel_chain.invoke({'text': input_text})\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nParallel execution took: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# --- DISPLAY THE RESULTS ---\n",
    "print(\"\\n--- Results ---\")\n",
    "print(f\"\\n[Summary]:\\n{results['summary']}\")\n",
    "print(f\"\\n[French Translation]:\\n{results['translation']}\")\n",
    "print(f\"\\n[Sentiment]:\\n{results['sentiment']}\")\n",
    "print(f\"\\n[Keywords]:\\n{results['keywords']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a97c3",
   "metadata": {},
   "source": [
    "### 4. Role playing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92c1f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(variables):\n",
    "    return prompt.format(**variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57d66cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"\"\"\n",
    "    Dungeon & Dragons game master\n",
    "\"\"\"\n",
    "\n",
    "tone = \"engaging and immersive\"\n",
    "\n",
    "template = \"\"\"\n",
    "    You are an expert {role}. I have this question {question}. I would like our conversation to be {tone}.\n",
    "    \n",
    "    Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "roleplay_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90a6fe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  (The air in my study is thick with the scent of old parchment and beeswax. A single lamp casts long shadows across shelves overflowing with tomes and strange artifacts. I lean back in my worn leather chair, steepling my fingers, and regard you with a knowing smile.)\n",
      "\n",
      "Ah, a question of *who* is the main actor, you say? A deceptively simple query, my friend. It's a question that has plagued philosophers and storytellers for centuries! In the grand theatre of life, and certainly in the grand theatre of Dungeons & Dragons, the answer isn't as straightforward as one might think.\n",
      "\n",
      "Tell me... when you ask \"main actor,\" what *specifically* do you mean? Are you asking about the character with the most narrative importance? The one with the most agency? The one the story revolves around? Or perhaps... the one *you*, as the player, invest the most in?\n",
      "\n",
      "Because you see, in D&D, the beauty ‚Äì and sometimes the chaos ‚Äì lies in the collaborative storytelling. It's not a play with a pre-written script and a single star. It's more like an improvisation troupe, building a world and a story *together*. \n",
      "\n",
      "However... (I pause, tapping a finger against my chin) ...if you're pressing me for a traditional answer, a single focal point... it often *defaults* to the character whose story is most deeply intertwined with the central conflict. The one who is, shall we say, most directly challenged by the forces at play.\n",
      "\n",
      "But even *that* can shift! A seemingly minor character can rise to prominence, a quiet observer can become a pivotal force. \n",
      "\n",
      "**To truly answer your question, I need to know a little more about *your* game.** \n",
      "\n",
      "Tell me:\n",
      "\n",
      "* **What campaign are you playing?** (Homebrew, a published module like Curse of Strahd, etc.)\n",
      "* **What is the central conflict of the campaign so far?** (What are the characters trying to achieve, or what is threatening them?)\n",
      "* **And, perhaps most importantly, who are the player characters?** (Just a brief overview of each will do - class, a defining trait, and maybe a little about their motivations.)\n",
      "\n",
      "\n",
      "\n",
      "Don't be shy. The more you tell me, the more accurately I can illuminate the stage and point you towards the true \"main actor\" ‚Äì or perhaps reveal that the very concept is an illusion!\n",
      "\n",
      "\n",
      "\n",
      "Now... tell me your tale. I'm listening.\n",
      "Answer: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Create an interactive chat loop\n",
    "while True:\n",
    "    query = input(\"Question: \")\n",
    "    \n",
    "    if query.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "        print(\"Answer: Goodbye!\")\n",
    "        break\n",
    "        \n",
    "    response = roleplay_chain.invoke({\"role\": role, \"question\": query, \"tone\": tone})\n",
    "    print(\"Answer: \", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
