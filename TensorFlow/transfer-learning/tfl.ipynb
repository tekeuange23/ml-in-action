{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bT0to3TL2q7H"
   },
   "source": [
    "# Ungraded Lab: Transfer Learning\n",
    "\n",
    "In this lab, you will see how you can use a pre-trained model to achieve good results even with a small training dataset. This is called _transfer learning_ and you do this by leveraging the trained layers of an existing model and adding your own layers to fit your application. For example, you can:\n",
    "\n",
    "1. just get the convolution layers of one model\n",
    "2. attach some dense layers onto it\n",
    "3. train just the dense network\n",
    "4. evaluate the results\n",
    "\n",
    "Doing this will allow you to save time building your application because you will essentially skip weeks of training time of very deep networks. You will just use the features it has learned and tweak it for your dataset. Let's see how these are done in the next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-12slkPL6_JH"
   },
   "source": [
    "## Setup the pretrained model\n",
    "\n",
    "You will need to prepare the pretrained model and configure the layers that you need. For this exercise, you will use the convolution layers of the [InceptionV3](https://arxiv.org/abs/1512.00567) architecture as your base model. To do that, you need to:\n",
    "\n",
    "1. Set the input shape to fit your application. In this case. set it to `150x150x3` as you've been doing in the last few labs.\n",
    "\n",
    "2. Pick and freeze the convolution layers to take advantage of the features it has learned already.\n",
    "\n",
    "3. Add dense layers which you will train.\n",
    "\n",
    "Let's see how to do these in the next cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VqhFEK2Y-PK"
   },
   "source": [
    "First, in preparing the input to the model, you want to fetch the pretrained weights of the `InceptionV3` model and remove the fully connected layer at the end because you will be replacing it later. You will also specify the input shape that your model will accept. Lastly, you want to freeze the weights of these layers because they have been trained already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [],
   "source": [
    "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
    "# The weights have been pre-downloaded for you from the following URL:\n",
    "# https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KsiBCpQ1VvPp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the weights file you downloaded into a variable\n",
    "local_weights_file = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Initialize the base model.\n",
    "# Set the input shape and remove the dense layers.\n",
    "pre_trained_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    input_shape = (150, 150, 3),\n",
    "    include_top = False,\n",
    "    weights = None)\n",
    "\n",
    "# Load the pre-trained weights you downloaded.\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Freeze the weights of the layers.\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y2rEnqFaa9k"
   },
   "source": [
    "You can see the summary of the model below. You can see that it is a very deep network. You can then select up to which point of the network you want to use. As Laurence showed in the exercise, you will use up to `mixed7` as your base model and add to that. This is because the original last layer might be too specialized in what it has learned so it might not translate well into your application. `mixed7` on the other hand will be more generalized and you can start with that for your application. After the exercise, feel free to modify and use other layers to see what the results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qeGP0Ust5kCR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)         (None, 74, 74, 32)           864       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_188 (B  (None, 74, 74, 32)           96        ['conv2d_188[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_188 (Activation  (None, 74, 74, 32)           0         ['batch_normalization_188[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)         (None, 72, 72, 32)           9216      ['activation_188[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_189 (B  (None, 72, 72, 32)           96        ['conv2d_189[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_189 (Activation  (None, 72, 72, 32)           0         ['batch_normalization_189[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)         (None, 72, 72, 64)           18432     ['activation_189[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_190 (B  (None, 72, 72, 64)           192       ['conv2d_190[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_190 (Activation  (None, 72, 72, 64)           0         ['batch_normalization_190[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 35, 35, 64)           0         ['activation_190[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)         (None, 35, 35, 80)           5120      ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_191 (B  (None, 35, 35, 80)           240       ['conv2d_191[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_191 (Activation  (None, 35, 35, 80)           0         ['batch_normalization_191[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)         (None, 33, 33, 192)          138240    ['activation_191[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_192 (B  (None, 33, 33, 192)          576       ['conv2d_192[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_192 (Activation  (None, 33, 33, 192)          0         ['batch_normalization_192[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 16, 16, 192)          0         ['activation_192[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_196 (B  (None, 16, 16, 64)           192       ['conv2d_196[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_196 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_196[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)         (None, 16, 16, 48)           9216      ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_196[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_194 (B  (None, 16, 16, 48)           144       ['conv2d_194[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_197 (B  (None, 16, 16, 96)           288       ['conv2d_197[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_194 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_194[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_197 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_197[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_18 (Aver  (None, 16, 16, 192)          0         ['max_pooling2d_9[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_194[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_197[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)         (None, 16, 16, 32)           6144      ['average_pooling2d_18[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_193 (B  (None, 16, 16, 64)           192       ['conv2d_193[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_195 (B  (None, 16, 16, 64)           192       ['conv2d_195[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_198 (B  (None, 16, 16, 96)           288       ['conv2d_198[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_199 (B  (None, 16, 16, 32)           96        ['conv2d_199[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_193 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_193[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_195 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_195[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_198 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_198[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_199 (Activation  (None, 16, 16, 32)           0         ['batch_normalization_199[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_193[0][0]',      \n",
      "                                                                     'activation_195[0][0]',      \n",
      "                                                                     'activation_198[0][0]',      \n",
      "                                                                     'activation_199[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_203 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_203 (B  (None, 16, 16, 64)           192       ['conv2d_203[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_203 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_203[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)         (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_204 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_203[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_201 (B  (None, 16, 16, 48)           144       ['conv2d_201[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_204 (B  (None, 16, 16, 96)           288       ['conv2d_204[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_201 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_201[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_204 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_204[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_19 (Aver  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_202 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_201[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_205 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_204[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_206 (Conv2D)         (None, 16, 16, 64)           16384     ['average_pooling2d_19[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_200 (B  (None, 16, 16, 64)           192       ['conv2d_200[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_202 (B  (None, 16, 16, 64)           192       ['conv2d_202[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_205 (B  (None, 16, 16, 96)           288       ['conv2d_205[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_206 (B  (None, 16, 16, 64)           192       ['conv2d_206[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_200 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_200[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_202 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_202[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_205 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_205[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_206 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_206[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_200[0][0]',      \n",
      "                                                                     'activation_202[0][0]',      \n",
      "                                                                     'activation_205[0][0]',      \n",
      "                                                                     'activation_206[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_210 (B  (None, 16, 16, 64)           192       ['conv2d_210[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_210 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_210[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_208 (Conv2D)         (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_210[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_208 (B  (None, 16, 16, 48)           144       ['conv2d_208[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_211 (B  (None, 16, 16, 96)           288       ['conv2d_211[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_208 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_208[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_211 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_211[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_20 (Aver  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_207 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_208[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_211[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)         (None, 16, 16, 64)           18432     ['average_pooling2d_20[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_207 (B  (None, 16, 16, 64)           192       ['conv2d_207[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_209 (B  (None, 16, 16, 64)           192       ['conv2d_209[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_212 (B  (None, 16, 16, 96)           288       ['conv2d_212[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_213 (B  (None, 16, 16, 64)           192       ['conv2d_213[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_207 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_207[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_209 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_209[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_212 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_212[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_213 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_213[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_207[0][0]',      \n",
      "                                                                     'activation_209[0][0]',      \n",
      "                                                                     'activation_212[0][0]',      \n",
      "                                                                     'activation_213[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_215 (B  (None, 16, 16, 64)           192       ['conv2d_215[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_215 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_215[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_215[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_216 (B  (None, 16, 16, 96)           288       ['conv2d_216[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_216 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_216[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)         (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_216[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_214 (B  (None, 7, 7, 384)            1152      ['conv2d_214[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_217 (B  (None, 7, 7, 96)             288       ['conv2d_217[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_214 (Activation  (None, 7, 7, 384)            0         ['batch_normalization_214[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_217 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_217[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 7, 7, 288)            0         ['mixed2[0][0]']              \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_214[0][0]',      \n",
      "                                                                     'activation_217[0][0]',      \n",
      "                                                                     'max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_222 (B  (None, 7, 7, 128)            384       ['conv2d_222[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_222 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_222[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_222[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_223 (B  (None, 7, 7, 128)            384       ['conv2d_223[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_223 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_223[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_223[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_219 (B  (None, 7, 7, 128)            384       ['conv2d_219[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_224 (B  (None, 7, 7, 128)            384       ['conv2d_224[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_219 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_219[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_224 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_224[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_219[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_224[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_220 (B  (None, 7, 7, 128)            384       ['conv2d_220[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_225 (B  (None, 7, 7, 128)            384       ['conv2d_225[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_220 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_220[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_225 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_225[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_21 (Aver  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_220[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_225[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_21[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_218 (B  (None, 7, 7, 192)            576       ['conv2d_218[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_221 (B  (None, 7, 7, 192)            576       ['conv2d_221[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_226 (B  (None, 7, 7, 192)            576       ['conv2d_226[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_227 (B  (None, 7, 7, 192)            576       ['conv2d_227[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_218 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_218[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_221 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_221[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_226 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_226[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_227 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_227[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_218[0][0]',      \n",
      "                                                                     'activation_221[0][0]',      \n",
      "                                                                     'activation_226[0][0]',      \n",
      "                                                                     'activation_227[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_232 (B  (None, 7, 7, 160)            480       ['conv2d_232[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_232 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_232[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_232[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_233 (B  (None, 7, 7, 160)            480       ['conv2d_233[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_233 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_233[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_233[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_229 (B  (None, 7, 7, 160)            480       ['conv2d_229[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_234 (B  (None, 7, 7, 160)            480       ['conv2d_234[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_229 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_229[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_234 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_234[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_229[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_234[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_230 (B  (None, 7, 7, 160)            480       ['conv2d_230[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_235 (B  (None, 7, 7, 160)            480       ['conv2d_235[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_230 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_230[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_235 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_235[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_22 (Aver  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_230[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_235[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_22[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_228 (B  (None, 7, 7, 192)            576       ['conv2d_228[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_231 (B  (None, 7, 7, 192)            576       ['conv2d_231[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_236 (B  (None, 7, 7, 192)            576       ['conv2d_236[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_237 (B  (None, 7, 7, 192)            576       ['conv2d_237[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_228 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_228[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_231 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_231[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_236 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_236[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_237 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_237[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_228[0][0]',      \n",
      "                                                                     'activation_231[0][0]',      \n",
      "                                                                     'activation_236[0][0]',      \n",
      "                                                                     'activation_237[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_242 (B  (None, 7, 7, 160)            480       ['conv2d_242[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_242 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_242[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_242[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_243 (B  (None, 7, 7, 160)            480       ['conv2d_243[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_243 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_243[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_243[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_239 (B  (None, 7, 7, 160)            480       ['conv2d_239[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_244 (B  (None, 7, 7, 160)            480       ['conv2d_244[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_239 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_239[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_244 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_244[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_239[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_244[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_240 (B  (None, 7, 7, 160)            480       ['conv2d_240[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_245 (B  (None, 7, 7, 160)            480       ['conv2d_245[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_240 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_240[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_245 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_245[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_23 (Aver  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_240[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_245[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_23[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_238 (B  (None, 7, 7, 192)            576       ['conv2d_238[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_241 (B  (None, 7, 7, 192)            576       ['conv2d_241[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_246 (B  (None, 7, 7, 192)            576       ['conv2d_246[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_247 (B  (None, 7, 7, 192)            576       ['conv2d_247[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_238 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_238[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_241 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_241[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_246 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_246[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_247 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_247[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_238[0][0]',      \n",
      "                                                                     'activation_241[0][0]',      \n",
      "                                                                     'activation_246[0][0]',      \n",
      "                                                                     'activation_247[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_252 (B  (None, 7, 7, 192)            576       ['conv2d_252[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_252 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_252[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_252[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_253 (B  (None, 7, 7, 192)            576       ['conv2d_253[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_253 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_253[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_253[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_249 (B  (None, 7, 7, 192)            576       ['conv2d_249[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_254 (B  (None, 7, 7, 192)            576       ['conv2d_254[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_249 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_249[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_254 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_254[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_249[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_254[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_250 (B  (None, 7, 7, 192)            576       ['conv2d_250[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_255 (B  (None, 7, 7, 192)            576       ['conv2d_255[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_250 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_250[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_255 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_255[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_24 (Aver  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_250[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_255[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_24[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_248 (B  (None, 7, 7, 192)            576       ['conv2d_248[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_251 (B  (None, 7, 7, 192)            576       ['conv2d_251[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_256 (B  (None, 7, 7, 192)            576       ['conv2d_256[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_257 (B  (None, 7, 7, 192)            576       ['conv2d_257[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_248 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_248[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_251 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_251[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_256 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_256[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_257 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_257[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_248[0][0]',      \n",
      "                                                                     'activation_251[0][0]',      \n",
      "                                                                     'activation_256[0][0]',      \n",
      "                                                                     'activation_257[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_260 (B  (None, 7, 7, 192)            576       ['conv2d_260[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_260 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_260[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_260[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_261 (B  (None, 7, 7, 192)            576       ['conv2d_261[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_261 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_261[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_258 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_261[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_258 (B  (None, 7, 7, 192)            576       ['conv2d_258[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_262 (B  (None, 7, 7, 192)            576       ['conv2d_262[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_258 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_258[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_262 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_262[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)         (None, 3, 3, 320)            552960    ['activation_258[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)         (None, 3, 3, 192)            331776    ['activation_262[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_259 (B  (None, 3, 3, 320)            960       ['conv2d_259[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_263 (B  (None, 3, 3, 192)            576       ['conv2d_263[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_259 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_259[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_263 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_263[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooli  (None, 3, 3, 768)            0         ['mixed7[0][0]']              \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)        (None, 3, 3, 1280)           0         ['activation_259[0][0]',      \n",
      "                                                                     'activation_263[0][0]',      \n",
      "                                                                     'max_pooling2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)         (None, 3, 3, 448)            573440    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_268 (B  (None, 3, 3, 448)            1344      ['conv2d_268[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_268 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_268[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)         (None, 3, 3, 384)            491520    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_268[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_265 (B  (None, 3, 3, 384)            1152      ['conv2d_265[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_269 (B  (None, 3, 3, 384)            1152      ['conv2d_269[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_265 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_265[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_269 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_269[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_265[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_265[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_269[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_269[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling2d_25 (Aver  (None, 3, 3, 1280)           0         ['mixed8[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)         (None, 3, 3, 320)            409600    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_266 (B  (None, 3, 3, 384)            1152      ['conv2d_266[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_267 (B  (None, 3, 3, 384)            1152      ['conv2d_267[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_270 (B  (None, 3, 3, 384)            1152      ['conv2d_270[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_271 (B  (None, 3, 3, 384)            1152      ['conv2d_271[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)         (None, 3, 3, 192)            245760    ['average_pooling2d_25[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_264 (B  (None, 3, 3, 320)            960       ['conv2d_264[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_266 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_266[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_267 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_267[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_270 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_270[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_271 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_271[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_272 (B  (None, 3, 3, 192)            576       ['conv2d_272[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_264 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_264[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)      (None, 3, 3, 768)            0         ['activation_266[0][0]',      \n",
      "                                                                     'activation_267[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 3, 3, 768)            0         ['activation_270[0][0]',      \n",
      " )                                                                   'activation_271[0][0]']      \n",
      "                                                                                                  \n",
      " activation_272 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_272[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)        (None, 3, 3, 2048)           0         ['activation_264[0][0]',      \n",
      "                                                                     'mixed9_0[0][0]',            \n",
      "                                                                     'concatenate_4[0][0]',       \n",
      "                                                                     'activation_272[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_277 (Conv2D)         (None, 3, 3, 448)            917504    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_277 (B  (None, 3, 3, 448)            1344      ['conv2d_277[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_277 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_277[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)         (None, 3, 3, 384)            786432    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_278 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_277[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_274 (B  (None, 3, 3, 384)            1152      ['conv2d_274[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_278 (B  (None, 3, 3, 384)            1152      ['conv2d_278[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_274 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_274[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_278 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_278[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_274[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_276 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_274[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_279 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_278[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_280 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_278[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling2d_26 (Aver  (None, 3, 3, 2048)           0         ['mixed9[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)         (None, 3, 3, 320)            655360    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_275 (B  (None, 3, 3, 384)            1152      ['conv2d_275[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_276 (B  (None, 3, 3, 384)            1152      ['conv2d_276[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_279 (B  (None, 3, 3, 384)            1152      ['conv2d_279[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_280 (B  (None, 3, 3, 384)            1152      ['conv2d_280[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_281 (Conv2D)         (None, 3, 3, 192)            393216    ['average_pooling2d_26[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_273 (B  (None, 3, 3, 320)            960       ['conv2d_273[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_275 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_275[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_276 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_276[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_279 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_279[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_280 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_280[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_281 (B  (None, 3, 3, 192)            576       ['conv2d_281[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_273 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_273[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)      (None, 3, 3, 768)            0         ['activation_275[0][0]',      \n",
      "                                                                     'activation_276[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 3, 3, 768)            0         ['activation_279[0][0]',      \n",
      " )                                                                   'activation_280[0][0]']      \n",
      "                                                                                                  \n",
      " activation_281 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_281[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)       (None, 3, 3, 2048)           0         ['activation_273[0][0]',      \n",
      "                                                                     'mixed9_1[0][0]',            \n",
      "                                                                     'concatenate_5[0][0]',       \n",
      "                                                                     'activation_281[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21802784 (83.17 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 21802784 (83.17 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jDmGO9tg5iPc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "# Choose `mixed7` as the last layer of your base model\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output.shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXT9SDMK7Ioa"
   },
   "source": [
    "## Add dense layers for your classifier\n",
    "\n",
    "Next, you will add dense layers to your model. These will be the layers that you will train and is tasked with recognizing cats and dogs. You will add a [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer as well to regularize the output and avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BMXb913pbvFg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)         (None, 74, 74, 32)           864       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_188 (B  (None, 74, 74, 32)           96        ['conv2d_188[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_188 (Activation  (None, 74, 74, 32)           0         ['batch_normalization_188[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)         (None, 72, 72, 32)           9216      ['activation_188[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_189 (B  (None, 72, 72, 32)           96        ['conv2d_189[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_189 (Activation  (None, 72, 72, 32)           0         ['batch_normalization_189[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)         (None, 72, 72, 64)           18432     ['activation_189[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_190 (B  (None, 72, 72, 64)           192       ['conv2d_190[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_190 (Activation  (None, 72, 72, 64)           0         ['batch_normalization_190[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 35, 35, 64)           0         ['activation_190[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)         (None, 35, 35, 80)           5120      ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_191 (B  (None, 35, 35, 80)           240       ['conv2d_191[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_191 (Activation  (None, 35, 35, 80)           0         ['batch_normalization_191[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)         (None, 33, 33, 192)          138240    ['activation_191[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_192 (B  (None, 33, 33, 192)          576       ['conv2d_192[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_192 (Activation  (None, 33, 33, 192)          0         ['batch_normalization_192[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 16, 16, 192)          0         ['activation_192[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_196 (B  (None, 16, 16, 64)           192       ['conv2d_196[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_196 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_196[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)         (None, 16, 16, 48)           9216      ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_196[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_194 (B  (None, 16, 16, 48)           144       ['conv2d_194[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_197 (B  (None, 16, 16, 96)           288       ['conv2d_197[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_194 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_194[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_197 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_197[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_18 (Aver  (None, 16, 16, 192)          0         ['max_pooling2d_9[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_194[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_197[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)         (None, 16, 16, 32)           6144      ['average_pooling2d_18[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_193 (B  (None, 16, 16, 64)           192       ['conv2d_193[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_195 (B  (None, 16, 16, 64)           192       ['conv2d_195[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_198 (B  (None, 16, 16, 96)           288       ['conv2d_198[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_199 (B  (None, 16, 16, 32)           96        ['conv2d_199[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_193 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_193[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_195 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_195[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_198 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_198[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_199 (Activation  (None, 16, 16, 32)           0         ['batch_normalization_199[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_193[0][0]',      \n",
      "                                                                     'activation_195[0][0]',      \n",
      "                                                                     'activation_198[0][0]',      \n",
      "                                                                     'activation_199[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_203 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_203 (B  (None, 16, 16, 64)           192       ['conv2d_203[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_203 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_203[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)         (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_204 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_203[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_201 (B  (None, 16, 16, 48)           144       ['conv2d_201[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_204 (B  (None, 16, 16, 96)           288       ['conv2d_204[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_201 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_201[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_204 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_204[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_19 (Aver  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_202 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_201[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_205 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_204[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_206 (Conv2D)         (None, 16, 16, 64)           16384     ['average_pooling2d_19[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_200 (B  (None, 16, 16, 64)           192       ['conv2d_200[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_202 (B  (None, 16, 16, 64)           192       ['conv2d_202[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_205 (B  (None, 16, 16, 96)           288       ['conv2d_205[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_206 (B  (None, 16, 16, 64)           192       ['conv2d_206[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_200 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_200[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_202 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_202[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_205 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_205[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_206 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_206[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_200[0][0]',      \n",
      "                                                                     'activation_202[0][0]',      \n",
      "                                                                     'activation_205[0][0]',      \n",
      "                                                                     'activation_206[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_210 (B  (None, 16, 16, 64)           192       ['conv2d_210[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_210 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_210[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_208 (Conv2D)         (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_210[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_208 (B  (None, 16, 16, 48)           144       ['conv2d_208[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_211 (B  (None, 16, 16, 96)           288       ['conv2d_211[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_208 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_208[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_211 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_211[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_20 (Aver  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_207 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_208[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_211[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)         (None, 16, 16, 64)           18432     ['average_pooling2d_20[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_207 (B  (None, 16, 16, 64)           192       ['conv2d_207[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_209 (B  (None, 16, 16, 64)           192       ['conv2d_209[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_212 (B  (None, 16, 16, 96)           288       ['conv2d_212[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_213 (B  (None, 16, 16, 64)           192       ['conv2d_213[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_207 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_207[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_209 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_209[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_212 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_212[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_213 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_213[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_207[0][0]',      \n",
      "                                                                     'activation_209[0][0]',      \n",
      "                                                                     'activation_212[0][0]',      \n",
      "                                                                     'activation_213[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_215 (B  (None, 16, 16, 64)           192       ['conv2d_215[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_215 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_215[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_215[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_216 (B  (None, 16, 16, 96)           288       ['conv2d_216[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_216 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_216[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)         (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_216[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_214 (B  (None, 7, 7, 384)            1152      ['conv2d_214[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_217 (B  (None, 7, 7, 96)             288       ['conv2d_217[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_214 (Activation  (None, 7, 7, 384)            0         ['batch_normalization_214[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_217 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_217[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 7, 7, 288)            0         ['mixed2[0][0]']              \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_214[0][0]',      \n",
      "                                                                     'activation_217[0][0]',      \n",
      "                                                                     'max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_222 (B  (None, 7, 7, 128)            384       ['conv2d_222[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_222 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_222[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_222[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_223 (B  (None, 7, 7, 128)            384       ['conv2d_223[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_223 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_223[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_223[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_219 (B  (None, 7, 7, 128)            384       ['conv2d_219[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_224 (B  (None, 7, 7, 128)            384       ['conv2d_224[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_219 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_219[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_224 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_224[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_219[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_224[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_220 (B  (None, 7, 7, 128)            384       ['conv2d_220[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_225 (B  (None, 7, 7, 128)            384       ['conv2d_225[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_220 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_220[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_225 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_225[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_21 (Aver  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_220[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_225[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_21[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_218 (B  (None, 7, 7, 192)            576       ['conv2d_218[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_221 (B  (None, 7, 7, 192)            576       ['conv2d_221[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_226 (B  (None, 7, 7, 192)            576       ['conv2d_226[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_227 (B  (None, 7, 7, 192)            576       ['conv2d_227[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_218 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_218[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_221 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_221[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_226 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_226[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_227 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_227[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_218[0][0]',      \n",
      "                                                                     'activation_221[0][0]',      \n",
      "                                                                     'activation_226[0][0]',      \n",
      "                                                                     'activation_227[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_232 (B  (None, 7, 7, 160)            480       ['conv2d_232[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_232 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_232[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_232[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_233 (B  (None, 7, 7, 160)            480       ['conv2d_233[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_233 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_233[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_233[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_229 (B  (None, 7, 7, 160)            480       ['conv2d_229[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_234 (B  (None, 7, 7, 160)            480       ['conv2d_234[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_229 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_229[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_234 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_234[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_229[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_234[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_230 (B  (None, 7, 7, 160)            480       ['conv2d_230[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_235 (B  (None, 7, 7, 160)            480       ['conv2d_235[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_230 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_230[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_235 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_235[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_22 (Aver  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_230[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_235[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_22[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_228 (B  (None, 7, 7, 192)            576       ['conv2d_228[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_231 (B  (None, 7, 7, 192)            576       ['conv2d_231[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_236 (B  (None, 7, 7, 192)            576       ['conv2d_236[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_237 (B  (None, 7, 7, 192)            576       ['conv2d_237[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_228 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_228[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_231 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_231[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_236 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_236[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_237 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_237[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_228[0][0]',      \n",
      "                                                                     'activation_231[0][0]',      \n",
      "                                                                     'activation_236[0][0]',      \n",
      "                                                                     'activation_237[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_242 (B  (None, 7, 7, 160)            480       ['conv2d_242[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_242 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_242[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_242[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_243 (B  (None, 7, 7, 160)            480       ['conv2d_243[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_243 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_243[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_243[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_239 (B  (None, 7, 7, 160)            480       ['conv2d_239[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_244 (B  (None, 7, 7, 160)            480       ['conv2d_244[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_239 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_239[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_244 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_244[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_239[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_244[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_240 (B  (None, 7, 7, 160)            480       ['conv2d_240[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_245 (B  (None, 7, 7, 160)            480       ['conv2d_245[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_240 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_240[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_245 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_245[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_23 (Aver  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_240[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_245[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_23[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_238 (B  (None, 7, 7, 192)            576       ['conv2d_238[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_241 (B  (None, 7, 7, 192)            576       ['conv2d_241[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_246 (B  (None, 7, 7, 192)            576       ['conv2d_246[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_247 (B  (None, 7, 7, 192)            576       ['conv2d_247[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_238 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_238[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_241 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_241[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_246 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_246[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_247 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_247[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_238[0][0]',      \n",
      "                                                                     'activation_241[0][0]',      \n",
      "                                                                     'activation_246[0][0]',      \n",
      "                                                                     'activation_247[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_252 (B  (None, 7, 7, 192)            576       ['conv2d_252[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_252 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_252[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_252[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_253 (B  (None, 7, 7, 192)            576       ['conv2d_253[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_253 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_253[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_253[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_249 (B  (None, 7, 7, 192)            576       ['conv2d_249[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_254 (B  (None, 7, 7, 192)            576       ['conv2d_254[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_249 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_249[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_254 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_254[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_249[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_254[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_250 (B  (None, 7, 7, 192)            576       ['conv2d_250[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_255 (B  (None, 7, 7, 192)            576       ['conv2d_255[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_250 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_250[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_255 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_255[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_24 (Aver  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_250[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_255[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_24[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_248 (B  (None, 7, 7, 192)            576       ['conv2d_248[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_251 (B  (None, 7, 7, 192)            576       ['conv2d_251[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_256 (B  (None, 7, 7, 192)            576       ['conv2d_256[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_257 (B  (None, 7, 7, 192)            576       ['conv2d_257[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_248 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_248[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_251 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_251[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_256 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_256[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_257 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_257[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_248[0][0]',      \n",
      "                                                                     'activation_251[0][0]',      \n",
      "                                                                     'activation_256[0][0]',      \n",
      "                                                                     'activation_257[0][0]']      \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 37632)                0         ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 3853619   ['flatten[0][0]']             \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1024)                 0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    1025      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 47512481 (181.25 MB)\n",
      "Trainable params: 38537217 (147.01 MB)\n",
      "Non-trainable params: 8975264 (34.24 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = tf.keras.layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = tf.keras.layers.Dense  (1, activation='sigmoid')(x)\n",
    "\n",
    "# Append the dense network to the base model\n",
    "model = tf.keras.Model(pre_trained_model.input, x)\n",
    "\n",
    "# Print the model summary. See your dense network connected at the end.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYLGw_RO7Z_X"
   },
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "Now you will prepare the dataset. This is basically the same code as the one you used in the data augmentation lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WOV8jON3c3Jv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = '../../datasets/cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join(BASE_DIR, 'train')\n",
    "validation_dir = os.path.join(BASE_DIR, 'validation')\n",
    "\n",
    "# Directory with training cat/dog pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with validation cat/dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Prepare the training set\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    label_mode='binary'\n",
    "    )\n",
    "\n",
    "# Prepare the validation set\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    label_mode='binary'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using pretrained models, you should make it a habit to check the documentation for any preprocessing steps. In this case, the [InceptionV3 documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/InceptionV3) says that the inputs should be scaled to the range [-1,1]. It has a [`preprocess_input()`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input)  method that you can use to rescale the inputs. The cell below defines a `preprocess` function that uses this method, which you can then map to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocess function\n",
    "def preprocess(image, label):\n",
    "    image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Apply the preprocessing to the datasets\n",
    "train_dataset_scaled = train_dataset.map(preprocess)\n",
    "validation_dataset_scaled = validation_dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the datasets for training\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset_final = (train_dataset_scaled\n",
    "                       .cache()\n",
    "                       .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                       .prefetch(PREFETCH_BUFFER_SIZE)\n",
    "                       )\n",
    "\n",
    "validation_dataset_final = (validation_dataset_scaled\n",
    "                            .cache()\n",
    "                            .prefetch(PREFETCH_BUFFER_SIZE)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ2I1nk398e5"
   },
   "source": [
    "## Prepare the Model for Training\n",
    "\n",
    "You will also add data augmentation layers to avoid your model from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6UnVzMxijYWu"
   },
   "outputs": [],
   "source": [
    "# Create a model with data augmentation layers\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.4),\n",
    "    tf.keras.layers.RandomTranslation(0.2,0.2),\n",
    "    tf.keras.layers.RandomContrast(0.4),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uCGopMv-m3Zb"
   },
   "outputs": [],
   "source": [
    "# Attach the data augmentation model to the base model\n",
    "inputs = tf.keras.Input(shape=(150, 150, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = model(x)\n",
    "\n",
    "model_with_aug = tf.keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGf3b-fK-tOl"
   },
   "source": [
    "Finally, you will compile the model with the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "A9ofMGh5kXMW"
   },
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model_with_aug.compile(\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m3S6AZb7h-B"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "With that, you can now train the model. You will do 20 epochs and plot the results afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 - 39s - loss: 0.6726 - accuracy: 0.6500 - val_loss: 0.1595 - val_accuracy: 0.9320 - 39s/epoch - 388ms/step\n",
      "Epoch 2/20\n",
      "100/100 - 31s - loss: 0.5313 - accuracy: 0.7310 - val_loss: 0.1314 - val_accuracy: 0.9320 - 31s/epoch - 314ms/step\n",
      "Epoch 3/20\n",
      "100/100 - 32s - loss: 0.5115 - accuracy: 0.7400 - val_loss: 0.1146 - val_accuracy: 0.9560 - 32s/epoch - 320ms/step\n",
      "Epoch 4/20\n",
      "100/100 - 32s - loss: 0.5041 - accuracy: 0.7525 - val_loss: 0.1039 - val_accuracy: 0.9550 - 32s/epoch - 318ms/step\n",
      "Epoch 5/20\n",
      "100/100 - 32s - loss: 0.4826 - accuracy: 0.7670 - val_loss: 0.1029 - val_accuracy: 0.9570 - 32s/epoch - 319ms/step\n",
      "Epoch 6/20\n",
      "100/100 - 32s - loss: 0.4656 - accuracy: 0.7695 - val_loss: 0.0922 - val_accuracy: 0.9600 - 32s/epoch - 318ms/step\n",
      "Epoch 7/20\n",
      "100/100 - 32s - loss: 0.4673 - accuracy: 0.7600 - val_loss: 0.1313 - val_accuracy: 0.9390 - 32s/epoch - 319ms/step\n",
      "Epoch 8/20\n",
      "100/100 - 33s - loss: 0.4415 - accuracy: 0.7860 - val_loss: 0.0968 - val_accuracy: 0.9630 - 33s/epoch - 333ms/step\n",
      "Epoch 9/20\n",
      "100/100 - 32s - loss: 0.4440 - accuracy: 0.7825 - val_loss: 0.0888 - val_accuracy: 0.9640 - 32s/epoch - 322ms/step\n",
      "Epoch 10/20\n",
      "100/100 - 33s - loss: 0.4474 - accuracy: 0.7910 - val_loss: 0.0948 - val_accuracy: 0.9550 - 33s/epoch - 330ms/step\n",
      "Epoch 11/20\n",
      "100/100 - 37s - loss: 0.4511 - accuracy: 0.7880 - val_loss: 0.0963 - val_accuracy: 0.9610 - 37s/epoch - 368ms/step\n",
      "Epoch 12/20\n",
      "100/100 - 32s - loss: 0.4439 - accuracy: 0.7785 - val_loss: 0.1036 - val_accuracy: 0.9640 - 32s/epoch - 320ms/step\n",
      "Epoch 13/20\n",
      "100/100 - 32s - loss: 0.4374 - accuracy: 0.7940 - val_loss: 0.1085 - val_accuracy: 0.9530 - 32s/epoch - 318ms/step\n",
      "Epoch 14/20\n",
      "100/100 - 32s - loss: 0.4336 - accuracy: 0.7925 - val_loss: 0.0987 - val_accuracy: 0.9600 - 32s/epoch - 324ms/step\n",
      "Epoch 15/20\n",
      "100/100 - 32s - loss: 0.4016 - accuracy: 0.8030 - val_loss: 0.0909 - val_accuracy: 0.9610 - 32s/epoch - 321ms/step\n",
      "Epoch 16/20\n",
      "100/100 - 32s - loss: 0.4247 - accuracy: 0.7890 - val_loss: 0.1189 - val_accuracy: 0.9510 - 32s/epoch - 322ms/step\n",
      "Epoch 17/20\n",
      "100/100 - 32s - loss: 0.4098 - accuracy: 0.8085 - val_loss: 0.1182 - val_accuracy: 0.9560 - 32s/epoch - 320ms/step\n",
      "Epoch 18/20\n",
      "100/100 - 32s - loss: 0.4355 - accuracy: 0.7950 - val_loss: 0.1195 - val_accuracy: 0.9500 - 32s/epoch - 322ms/step\n",
      "Epoch 19/20\n",
      "100/100 - 32s - loss: 0.4225 - accuracy: 0.8040 - val_loss: 0.1164 - val_accuracy: 0.9530 - 32s/epoch - 319ms/step\n",
      "Epoch 20/20\n",
      "100/100 - 32s - loss: 0.4150 - accuracy: 0.8080 - val_loss: 0.1155 - val_accuracy: 0.9530 - 32s/epoch - 320ms/step\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# Train the model.\n",
    "history = model_with_aug.fit(\n",
    "    train_dataset_final,\n",
    "    validation_data = validation_dataset_final,\n",
    "    epochs = EPOCHS,\n",
    "    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwcB2bPj7lIx"
   },
   "source": [
    "## Evaluate the results\n",
    "\n",
    "You will use the same code to plot the results. As you can see, the validation accuracy is steady at around 95% even as your training accuracy improves. This is a good sign that your model is not overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(history):\n",
    "    '''Plots the training and validation loss and accuracy from a history object'''\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "    ax[0].plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    ax[0].set_title('Training and validation accuracy')\n",
    "    ax[0].set_xlabel('epochs')\n",
    "    ax[0].set_ylabel('accuracy')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].plot(epochs, loss, 'bo', label='Training Loss')\n",
    "    ax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    ax[1].set_title('Training and validation loss')\n",
    "    ax[1].set_xlabel('epochs')\n",
    "    ax[1].set_ylabel('loss')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_loss_acc(history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "cuda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
